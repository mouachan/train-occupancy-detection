apiVersion: serving.kserve.io/v1beta1
kind: InferenceService
metadata:
  name: train-detection-model
  labels:
    opendatahub.io/dashboard: "true"
  annotations:
    serving.kserve.io/deploymentMode: RawDeployment
    security.opendatahub.io/enable-auth: "false"
    openshift.io/display-name: train-detection-model
    openshift.io/description: "YOLOv11 person detection model for train occupancy monitoring"
    serving.kserve.io/enable-prometheus-scraping: "false"
spec:
  predictor:
    serviceAccountName: s3-credentials-sa
    model:
      modelFormat:
        name: onnx
        version: "1"
      runtime: triton-runtime
      # Triton model repository path in S3
      # Storage initializer will download s3://models/model/* to /mnt/models/
      # Structure in S3: s3://models/model/yolo11n/1/model.onnx
      # Results in container: /mnt/models/yolo11n/1/model.onnx
      storageUri: s3://models/model
      resources:
        requests:
          memory: 4Gi
          cpu: "2"
        limits:
          memory: 4Gi
          cpu: "2"
    minReplicas: 1
    maxReplicas: 3
    scaleTarget: 80
    scaleMetric: concurrency
