apiVersion: serving.kserve.io/v1beta1
kind: InferenceService
metadata:
  name: train-person-detection
  namespace: train-detection
  labels:
    app: train-detection
    model: yolo11
  annotations:
    serving.kserve.io/deploymentMode: RawDeployment
    serving.knative.openshift.io/enablePassthrough: "true"
    description: "YOLOv11 person detection model for train occupancy monitoring"
spec:
  predictor:
    model:
      modelFormat:
        name: onnx
        version: "1"
      runtime: triton-runtime
      # Triton model repository - MUST be bucket root
      # KServe downloads CONTENTS of storageUri to /mnt/models/
      # Structure in S3: s3://models/yolo11n/1/model.onnx
      # Results in container: /mnt/models/yolo11n/1/model.onnx
      storageUri: s3://models
      resources:
        requests:
          memory: 2Gi
          cpu: 1
        limits:
          memory: 4Gi
          cpu: 2
    minReplicas: 1
    maxReplicas: 3
    scaleTarget: 80
    scaleMetric: concurrency
