apiVersion: v1
kind: ConfigMap
metadata:
  name: streamlit-config
  namespace: train-detection
  labels:
    app: train-detection-streamlit
data:
  # KServe endpoint URL (external route)
  # Use the InferenceService route URL (same as notebooks)
  kserve_endpoint: "https://train-detection-model-train-detection.apps.cluster-rk6mx.rk6mx.sandbox492.opentlc.com"

  # Model name in Triton (directory name in S3: models/yolo11n/)
  model_name: "yolo11n"

  # Detection settings
  confidence_threshold: "0.25"

  # Upload settings
  max_upload_size_mb: "500"
