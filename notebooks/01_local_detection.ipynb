{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLOv11 Local Person Detection\n",
    "\n",
    "This notebook demonstrates person detection using YOLOv11 model in embedded/local mode.\n",
    "\n",
    "## Features:\n",
    "- Load YOLOv11 model\n",
    "- Process sample images and videos\n",
    "- Visualize detections with bounding boxes\n",
    "- Calculate performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "import time\n",
    "\n",
    "from src.detection.yolo_detector import YOLODetector\n",
    "from src.detection.visualizer import draw_detections, create_detection_summary, draw_summary_on_frame\n",
    "from src.utils.config import Config\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (12, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Download and Load YOLOv11 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download YOLOv11n model (smallest, fastest)\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# This will download the model if not present\n",
    "model = YOLO('yolo11n.pt')\n",
    "print(f\"Model loaded successfully\")\n",
    "\n",
    "# Save to models directory\n",
    "Config.ensure_directories()\n",
    "model_path = Config.get_model_path('yolo11n.pt')\n",
    "if not model_path.exists():\n",
    "    import shutil\n",
    "    shutil.copy('yolo11n.pt', model_path)\n",
    "    print(f\"Model saved to: {model_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initialize Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize YOLODetector\n",
    "detector = YOLODetector(\n",
    "    model_path=str(Config.get_model_path('yolo11n.pt')),\n",
    "    conf_threshold=0.25,\n",
    "    device='cpu'  # Change to 'cuda' or 'mps' for GPU\n",
    ")\n",
    "\n",
    "print(\"Detector initialized\")\n",
    "print(\"Model info:\", detector.get_model_info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Test on Sample Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download a sample image with people\n",
    "import urllib.request\n",
    "\n",
    "sample_image_url = \"https://ultralytics.com/images/bus.jpg\"\n",
    "sample_image_path = \"sample_image.jpg\"\n",
    "\n",
    "urllib.request.urlretrieve(sample_image_url, sample_image_path)\n",
    "print(f\"Downloaded sample image to: {sample_image_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process image\n",
    "start_time = time.time()\n",
    "image, detections = detector.process_image(sample_image_path)\n",
    "inference_time = (time.time() - start_time) * 1000\n",
    "\n",
    "print(f\"Inference time: {inference_time:.2f} ms\")\n",
    "print(f\"Number of persons detected: {len(detections)}\")\n",
    "\n",
    "# Print detection details\n",
    "for i, det in enumerate(detections):\n",
    "    print(f\"Person {i+1}: confidence={det.confidence:.2f}, bbox={[round(x, 1) for x in det.bbox]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize detections\n",
    "annotated_image = draw_detections(image, detections)\n",
    "\n",
    "# Convert BGR to RGB for matplotlib\n",
    "annotated_rgb = cv2.cvtColor(annotated_image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.figure(figsize=(14, 10))\n",
    "plt.imshow(annotated_rgb)\n",
    "plt.title(f\"Detected {len(detections)} persons - Inference time: {inference_time:.2f} ms\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Detection Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create detection summary\n",
    "summary = create_detection_summary(detections)\n",
    "\n",
    "print(\"Detection Summary:\")\n",
    "for key, value in summary.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Draw summary on frame\n",
    "annotated_with_summary = draw_summary_on_frame(annotated_image, summary)\n",
    "summary_rgb = cv2.cvtColor(annotated_with_summary, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "plt.figure(figsize=(14, 10))\n",
    "plt.imshow(summary_rgb)\n",
    "plt.title(\"Detection with Summary Overlay\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Process Video (if available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: You need to provide a video file for this section\n",
    "# You can download a sample or use your own train video\n",
    "\n",
    "video_path = \"sample_video.mp4\"  # Update this path\n",
    "\n",
    "if Path(video_path).exists():\n",
    "    print(f\"Processing video: {video_path}\")\n",
    "    \n",
    "    frame_count = 0\n",
    "    total_detections = 0\n",
    "    total_time = 0\n",
    "    \n",
    "    # Process first 100 frames for demo\n",
    "    for frame, detections in detector.process_video(video_path, skip_frames=2):\n",
    "        if frame_count >= 100:\n",
    "            break\n",
    "        \n",
    "        frame_count += 1\n",
    "        total_detections += len(detections)\n",
    "        \n",
    "        # Display every 10th frame\n",
    "        if frame_count % 10 == 0:\n",
    "            annotated = draw_detections(frame, detections)\n",
    "            summary = create_detection_summary(detections)\n",
    "            annotated = draw_summary_on_frame(annotated, summary)\n",
    "            \n",
    "            plt.figure(figsize=(12, 8))\n",
    "            plt.imshow(cv2.cvtColor(annotated, cv2.COLOR_BGR2RGB))\n",
    "            plt.title(f\"Frame {frame_count}: {len(detections)} persons detected\")\n",
    "            plt.axis('off')\n",
    "            plt.show()\n",
    "    \n",
    "    print(f\"\\nProcessed {frame_count} frames\")\n",
    "    print(f\"Total detections: {total_detections}\")\n",
    "    print(f\"Average detections per frame: {total_detections/frame_count:.2f}\")\n",
    "else:\n",
    "    print(f\"Video file not found: {video_path}\")\n",
    "    print(\"Please provide a video file to test video processing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Performance Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Benchmark inference speed\n",
    "num_runs = 10\n",
    "times = []\n",
    "\n",
    "print(f\"Running {num_runs} inference iterations...\")\n",
    "for i in range(num_runs):\n",
    "    start = time.time()\n",
    "    detections = detector.detect_persons(image)\n",
    "    elapsed = (time.time() - start) * 1000\n",
    "    times.append(elapsed)\n",
    "\n",
    "print(f\"\\nBenchmark Results ({num_runs} runs):\")\n",
    "print(f\"  Average: {np.mean(times):.2f} ms\")\n",
    "print(f\"  Min: {np.min(times):.2f} ms\")\n",
    "print(f\"  Max: {np.max(times):.2f} ms\")\n",
    "print(f\"  Std: {np.std(times):.2f} ms\")\n",
    "print(f\"  FPS: {1000/np.mean(times):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "- Loading YOLOv11 model for person detection\n",
    "- Processing images with bounding box visualization\n",
    "- Generating detection statistics\n",
    "- Video processing capabilities\n",
    "- Performance benchmarking\n",
    "\n",
    "Next: See `02_api_detection.ipynb` for REST API inference testing."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
