{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export YOLOv11 to ONNX and Upload to S3/MinIO\n",
    "\n",
    "This notebook demonstrates:\n",
    "- Exporting YOLOv11 model to ONNX format\n",
    "- Uploading the ONNX model to S3/MinIO storage\n",
    "- Using environment variables for configuration\n",
    "\n",
    "## Prerequisites\n",
    "Set the following environment variables before running:\n",
    "- `AWS_ACCESS_KEY_ID`: S3 access key\n",
    "- `AWS_SECRET_ACCESS_KEY`: S3 secret key\n",
    "- `AWS_S3_ENDPOINT`: S3 endpoint URL\n",
    "- `AWS_S3_BUCKET`: S3 bucket name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "from ultralytics import YOLO\n",
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "print(\"Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration from Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get configuration from environment variables\n",
    "AWS_ACCESS_KEY_ID = os.getenv('AWS_ACCESS_KEY_ID')\n",
    "AWS_SECRET_ACCESS_KEY = os.getenv('AWS_SECRET_ACCESS_KEY')\n",
    "AWS_S3_ENDPOINT = os.getenv('AWS_S3_ENDPOINT')\n",
    "AWS_S3_BUCKET = os.getenv('AWS_S3_BUCKET', 'models')  # Default to 'models'\n",
    "AWS_DEFAULT_REGION = os.getenv('AWS_DEFAULT_REGION', 'us-east-1')\n",
    "\n",
    "# Validate configuration\n",
    "print(\"Configuration:\")\n",
    "print(f\"  AWS_ACCESS_KEY_ID: {'‚úì Set' if AWS_ACCESS_KEY_ID else '‚úó Not set'}\")\n",
    "print(f\"  AWS_SECRET_ACCESS_KEY: {'‚úì Set' if AWS_SECRET_ACCESS_KEY else '‚úó Not set'}\")\n",
    "print(f\"  AWS_S3_ENDPOINT: {AWS_S3_ENDPOINT or '‚úó Not set'}\")\n",
    "print(f\"  AWS_S3_BUCKET: {AWS_S3_BUCKET}\")\n",
    "print(f\"  AWS_DEFAULT_REGION: {AWS_DEFAULT_REGION}\")\n",
    "\n",
    "if not all([AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY, AWS_S3_ENDPOINT]):\n",
    "    print(\"\\n‚ö†Ô∏è  Warning: Some environment variables are not set!\")\n",
    "    print(\"Please set AWS_ACCESS_KEY_ID, AWS_SECRET_ACCESS_KEY, and AWS_S3_ENDPOINT\")\n",
    "else:\n",
    "    print(\"\\n‚úì All required environment variables are set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Download YOLOv11 Model (if not present)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "MODELS_DIR = Path('../models')\n",
    "MODELS_DIR.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "MODEL_PT_PATH = MODELS_DIR / 'yolo11n.pt'\n",
    "MODEL_ONNX_PATH = MODELS_DIR / 'yolo11n.onnx'\n",
    "\n",
    "print(f\"Models directory: {MODELS_DIR.absolute()}\")\n",
    "print(f\"PyTorch model path: {MODEL_PT_PATH}\")\n",
    "print(f\"ONNX model path: {MODEL_ONNX_PATH}\")\n",
    "\n",
    "# Download model if not present\n",
    "if not MODEL_PT_PATH.exists():\n",
    "    print(\"\\nDownloading YOLOv11n model...\")\n",
    "    \n",
    "    # Change to models directory to download there (avoids permission issues)\n",
    "    original_dir = os.getcwd()\n",
    "    os.chdir(MODELS_DIR)\n",
    "    \n",
    "    try:\n",
    "        model = YOLO('yolo11n.pt')\n",
    "        print(f\"‚úì Model downloaded to {MODEL_PT_PATH}\")\n",
    "    finally:\n",
    "        # Return to original directory\n",
    "        os.chdir(original_dir)\n",
    "else:\n",
    "    print(f\"\\n‚úì Model already exists at {MODEL_PT_PATH}\")\n",
    "    print(f\"  Size: {MODEL_PT_PATH.stat().st_size / (1024**2):.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Export Model to ONNX Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export parameters\n",
    "EXPORT_PARAMS = {\n",
    "    'format': 'onnx',\n",
    "    'imgsz': 640,\n",
    "    'dynamic': True,\n",
    "    'simplify': True,\n",
    "    'opset': 17\n",
    "}\n",
    "\n",
    "print(\"Export configuration:\")\n",
    "for key, value in EXPORT_PARAMS.items():\n",
    "    print(f\"  {key}: {value}\")\n",
    "\n",
    "# Load model\n",
    "print(f\"\\nLoading model from {MODEL_PT_PATH}...\")\n",
    "model = YOLO(str(MODEL_PT_PATH))\n",
    "\n",
    "# Export to ONNX\n",
    "print(\"\\nExporting to ONNX format...\")\n",
    "print(\"This may take a few minutes...\\n\")\n",
    "\n",
    "exported_path = model.export(**EXPORT_PARAMS)\n",
    "\n",
    "print(f\"\\n‚úì Export successful!\")\n",
    "print(f\"  Exported to: {exported_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move ONNX file to models directory if needed\n",
    "import shutil\n",
    "\n",
    "exported_path = Path(exported_path)\n",
    "if exported_path != MODEL_ONNX_PATH:\n",
    "    print(f\"Moving {exported_path} to {MODEL_ONNX_PATH}...\")\n",
    "    if MODEL_ONNX_PATH.exists():\n",
    "        MODEL_ONNX_PATH.unlink()\n",
    "    shutil.move(str(exported_path), str(MODEL_ONNX_PATH))\n",
    "    print(\"‚úì Model moved\")\n",
    "\n",
    "# Display model info\n",
    "model_size_mb = MODEL_ONNX_PATH.stat().st_size / (1024**2)\n",
    "print(f\"\\nONNX Model Information:\")\n",
    "print(f\"  Path: {MODEL_ONNX_PATH}\")\n",
    "print(f\"  Size: {model_size_mb:.2f} MB\")\n",
    "print(f\"  Format: ONNX\")\n",
    "print(f\"  Input size: 640x640\")\n",
    "print(f\"  Dynamic shapes: Enabled\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Upload Model to S3/MinIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize S3 client\n",
    "print(\"Initializing S3 client...\")\n",
    "print(f\"  Endpoint: {AWS_S3_ENDPOINT}\")\n",
    "print(f\"  Region: {AWS_DEFAULT_REGION}\")\n",
    "\n",
    "s3_client = boto3.client(\n",
    "    's3',\n",
    "    endpoint_url=AWS_S3_ENDPOINT,\n",
    "    region_name=AWS_DEFAULT_REGION,\n",
    "    aws_access_key_id=AWS_ACCESS_KEY_ID,\n",
    "    aws_secret_access_key=AWS_SECRET_ACCESS_KEY\n",
    ")\n",
    "\n",
    "print(\"‚úì S3 client initialized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if bucket exists\n",
    "print(f\"\\nChecking bucket '{AWS_S3_BUCKET}'...\")\n",
    "\n",
    "try:\n",
    "    s3_client.head_bucket(Bucket=AWS_S3_BUCKET)\n",
    "    print(f\"‚úì Bucket '{AWS_S3_BUCKET}' exists\")\n",
    "except ClientError as e:\n",
    "    error_code = e.response['Error']['Code']\n",
    "    if error_code == '404':\n",
    "        print(f\"Bucket '{AWS_S3_BUCKET}' not found, creating...\")\n",
    "        try:\n",
    "            s3_client.create_bucket(Bucket=AWS_S3_BUCKET)\n",
    "            print(f\"‚úì Bucket '{AWS_S3_BUCKET}' created\")\n",
    "        except ClientError as create_error:\n",
    "            print(f\"‚úó Failed to create bucket: {create_error}\")\n",
    "            raise\n",
    "    else:\n",
    "        print(f\"‚úó Error checking bucket: {e}\")\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload model\n",
    "object_key = MODEL_ONNX_PATH.name\n",
    "s3_uri = f\"s3://{AWS_S3_BUCKET}/{object_key}\"\n",
    "\n",
    "print(f\"\\nUploading model to S3...\")\n",
    "print(f\"  Source: {MODEL_ONNX_PATH}\")\n",
    "print(f\"  Destination: {s3_uri}\")\n",
    "print(f\"  Size: {model_size_mb:.2f} MB\")\n",
    "print(\"\\nUploading...\")\n",
    "\n",
    "try:\n",
    "    # Upload file (using upload_file for better MinIO compatibility)\n",
    "    s3_client.upload_file(\n",
    "        str(MODEL_ONNX_PATH),\n",
    "        AWS_S3_BUCKET,\n",
    "        object_key\n",
    "    )\n",
    "    \n",
    "    print(\"\\n‚úì Upload successful!\")\n",
    "    print(f\"\\nModel location:\")\n",
    "    print(f\"  S3 URI: {s3_uri}\")\n",
    "    print(f\"  Endpoint: {AWS_S3_ENDPOINT}\")\n",
    "    print(f\"  Bucket: {AWS_S3_BUCKET}\")\n",
    "    print(f\"  Key: {object_key}\")\n",
    "    \n",
    "except ClientError as e:\n",
    "    print(f\"\\n‚úó Upload failed: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Verify Upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the object exists in S3\n",
    "print(\"Verifying upload...\\n\")\n",
    "\n",
    "try:\n",
    "    response = s3_client.head_object(Bucket=AWS_S3_BUCKET, Key=object_key)\n",
    "    \n",
    "    print(\"‚úì Object verified in S3\")\n",
    "    print(f\"\\nObject metadata:\")\n",
    "    print(f\"  Content-Length: {response['ContentLength'] / (1024**2):.2f} MB\")\n",
    "    print(f\"  Content-Type: {response.get('ContentType', 'N/A')}\")\n",
    "    print(f\"  ETag: {response.get('ETag', 'N/A')}\")\n",
    "    print(f\"  Last-Modified: {response.get('LastModified', 'N/A')}\")\n",
    "    \n",
    "except ClientError as e:\n",
    "    print(f\"‚úó Verification failed: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. List All Objects in Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all objects in the bucket\n",
    "print(f\"Objects in bucket '{AWS_S3_BUCKET}':\\n\")\n",
    "\n",
    "try:\n",
    "    response = s3_client.list_objects_v2(Bucket=AWS_S3_BUCKET)\n",
    "    \n",
    "    if 'Contents' in response:\n",
    "        for obj in response['Contents']:\n",
    "            size_mb = obj['Size'] / (1024**2)\n",
    "            print(f\"  üìÑ {obj['Key']}\")\n",
    "            print(f\"     Size: {size_mb:.2f} MB\")\n",
    "            print(f\"     Last Modified: {obj['LastModified']}\")\n",
    "            print()\n",
    "    else:\n",
    "        print(\"  (empty bucket)\")\n",
    "        \n",
    "except ClientError as e:\n",
    "    print(f\"‚úó Failed to list objects: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Generate InferenceService YAML\n",
    "\n",
    "Generate the YAML configuration for deploying on OpenShift AI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate InferenceService YAML\n",
    "inference_service_yaml = f\"\"\"apiVersion: serving.kserve.io/v1beta1\n",
    "kind: InferenceService\n",
    "metadata:\n",
    "  name: yolo11-person-detection\n",
    "  namespace: train-detection\n",
    "  labels:\n",
    "    app: train-detection\n",
    "    model: yolo11\n",
    "  annotations:\n",
    "    serving.kserve.io/deploymentMode: RawDeployment\n",
    "    serving.knative.openshift.io/enablePassthrough: \"true\"\n",
    "spec:\n",
    "  predictor:\n",
    "    model:\n",
    "      modelFormat:\n",
    "        name: onnx\n",
    "        version: \"1\"\n",
    "      runtime: yolo11-triton-runtime\n",
    "      storageUri: {s3_uri}\n",
    "      resources:\n",
    "        requests:\n",
    "          memory: 2Gi\n",
    "          cpu: 1\n",
    "        limits:\n",
    "          memory: 4Gi\n",
    "          cpu: 2\n",
    "    minReplicas: 1\n",
    "    maxReplicas: 3\n",
    "\"\"\"\n",
    "\n",
    "print(\"Generated InferenceService YAML:\")\n",
    "print(\"=\" * 70)\n",
    "print(inference_service_yaml)\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Save to file\n",
    "yaml_path = Path('../openshift/model-serving/inference-service-generated.yaml')\n",
    "with open(yaml_path, 'w') as f:\n",
    "    f.write(inference_service_yaml)\n",
    "\n",
    "print(f\"\\n‚úì YAML saved to: {yaml_path}\")\n",
    "print(\"\\nTo deploy, run:\")\n",
    "print(f\"  oc apply -f {yaml_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook:\n",
    "1. ‚úì Loaded configuration from environment variables\n",
    "2. ‚úì Downloaded YOLOv11 model (if needed)\n",
    "3. ‚úì Exported model to ONNX format\n",
    "4. ‚úì Uploaded ONNX model to S3/MinIO\n",
    "5. ‚úì Verified the upload\n",
    "6. ‚úì Generated InferenceService YAML\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. **Deploy ServingRuntime** (if not already deployed):\n",
    "   ```bash\n",
    "   oc apply -f ../openshift/model-serving/serving-runtime.yaml\n",
    "   ```\n",
    "\n",
    "2. **Deploy InferenceService**:\n",
    "   ```bash\n",
    "   oc apply -f ../openshift/model-serving/inference-service-generated.yaml\n",
    "   ```\n",
    "\n",
    "3. **Check deployment status**:\n",
    "   ```bash\n",
    "   oc get inferenceservice yolo11-person-detection -w\n",
    "   ```\n",
    "\n",
    "4. **Test the API** using `notebooks/03_api_detection.ipynb`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
